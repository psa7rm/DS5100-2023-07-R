{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: Basic File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Objectives**\n",
    "\n",
    "- Demonstrate use of Python's `open()` function\n",
    "- Show pattern using loops, comprehensions, and string operations to import a CSV\n",
    "- Show how to parse an imported CSV into a 2D list\n",
    "- Show how to convert a 2D list into a 2D Numpy array\n",
    "- Describe the difficulties associated with this importing CSV files using basic Python\n",
    "\n",
    "## Open Files with `open()`\n",
    "\n",
    "Let's open a sample CSV file, `biostats.csv`.\n",
    "\n",
    "* This has some biometric statistics for a group of office workers. \n",
    "* There are 18 records, recording Name, Sex, Age, Height, Weight \n",
    "* There is an initial header line.\n",
    "* This file was downloaded from https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html and modified slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file_name = \"./sample_data_files/biostats.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the `open()` function and pass it two parameters:\n",
    "* The name of the file we want to open.\n",
    "* The mode in which the file is opened. It defaults to `r` which means open for reading in text\n",
    "mode. Other common values are:\n",
    "  * `w` for writing (truncating the file if it already exists)\n",
    "  * `x` for creating and writing to a new file \n",
    "  * `a` for appending\n",
    "\n",
    "The returns a file object whose type depends on the mode and\n",
    "through which the standard file operations such as reading and writing\n",
    "are performed. So, to read from the file, you need to have specified type `r` and to write you need to have specified `w`.\n",
    "\n",
    "The file object is an iterator.\n",
    "\n",
    "For more info, check out [the Python docs](https://docs.python.org/3/library/functions.html#open) or run `open?` from a code cell.\n",
    "\n",
    "Note, we sometimes call the file object a file \"handle.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open(src_file_name, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.read()` reads in the file as one long string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_as_big_string = file_handle.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_as_big_string[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file object is an iterator, we can't get the string again from the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_as_big_string = file_handle.read() # Try reading from the handle again\n",
    "file_as_big_string[:1000] # Nothing there since the iterator is exhausted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's create a new handle, read in the contents again, and then parse our string by newlines using `.split(\"\\n\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open(\"./sample_data_files/biostats.csv\", 'r')\n",
    "file_as_big_string = file_handle.read()\n",
    "file_as_big_string.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short-cut to this process is to call the `.readlines()` method, which returns a pre-made list of lines.\n",
    "\n",
    "Note that the newlines are preserved in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle = open(src_file_name, 'r')\n",
    "file_as_list_of_strings = file_handle.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_as_list_of_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File objects should be closed when you are done with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a `with` block \n",
    "\n",
    "... to automatically open and close the file i/o object\n",
    "\n",
    "There is a better way to handle objects that need to be closed.\n",
    "\n",
    "Other examples of such objects are database handles.\n",
    "\n",
    "`with` will automatically open and close the file handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(src_file_name, 'r') as infile:\n",
    "    file_as_list = infile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_as_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert into a 2D list\n",
    "\n",
    "Let's covert our list of strings to a list of lists, the former being the rows of data table and the latter the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%time\n",
    "list_2d = []\n",
    "with open(src_file_name, 'r') as infile:\n",
    "    for line in infile.readlines():\n",
    "        row = line.rstrip().split(\",\") # Note the use of rstrip()\n",
    "        list_2d.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we now have do something with the column names and handle formating and casting each cell.\n",
    "\n",
    "## Using a list comprehension\n",
    "\n",
    "We can replace the entire code block above nested list comprehensions.\n",
    "\n",
    "Remember, you can put any expression into the first part of a comprehension, even another comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2d = [[cell.strip() for cell in line.rstrip().replace('\"', '').split(\",\")] \n",
    "        for line in open(src_file_name, 'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays must be of the same data types, and it also has no concept of column names, so we remove this row from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list_2d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix = np.array(list_2d[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate slicing along both dimensions.\n",
    "\n",
    "## Array Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix[:2, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data Types\n",
    "\n",
    "Let's try to convert the data types of the numeric columns from strings to integers. One thing we might do is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix[:, 2:5].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the strings are converted to integers.\n",
    "\n",
    "So, let's try to save the conversion results to the original array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix[:, 2:5] = np_matrix[:, 2:5].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?\n",
    "\n",
    "## Some Difficulties\n",
    "\n",
    "It is pretty easy to import CSV files this way, but there are many difficulties you are likely to encounter if you use this as your default pattern for importing data. Here are just a few:\n",
    "- **Not all sources are well-formed**. They may have delimitters that are complex to parse, and the the data themselve may be hard to parse.\n",
    "- **You have to keep the column names in a separate list or vector** and then associate them with the data if and when necessary.\n",
    "- **You have to convert each column vector into its appropriate data type yourself.** Or, you have to create separate 2D arrays for each collection of columns with a common data type. This process also invovles human inspection of the file, as opposed to have a program try to figure it out for you.\n",
    "\n",
    "For these reasons, other tools such as Pandas were created to make the work of a data scientist a bit easier and more productive.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
